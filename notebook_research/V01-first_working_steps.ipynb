{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Working steps\n",
    "First working steps in getting to know the Dataframe Interchange Protocol and how to implement it to Vaex library for simple int and float without missing and chunking.\n",
    "\n",
    "- **2021/07/12**\n",
    "Researching `test_float_only()` from `pandas_implementation.py`. Learning about Vaex with collecting data into a Vaex dataframe, researching possible ways to do it. I started with two options to construct a dataframe from `np.array` and from `dict` (`vaex.from_arrays()` and `vaex.from_dict()`). \n",
    "\n",
    "- **2021/07/13**\n",
    "Adding `from_dataframe()` method that calls `_from_dataframe()` if `df` is not a `vaex` type dataframe. Dataframe in `vaex` is specified as `vaex.dataframe.DataFrame`. `DataFrameObject` is type `Any` (typing library). Also ` _VaexDataFrame` was added.\n",
    "\n",
    "- **2021/07/14**\n",
    "Adding `_from_dataframe()` method.\n",
    "\n",
    "    The method goes through the columns one by one by the column name. It checks the data type in the column and then converts each column to match `vaex` column type. I will have to check which arrays are supported in `vaex` (ndarray, arrow array, ...). Two methods used in Pandas implementation are `convert_column_to_ndarray()` and`convert_categorical_column()`. I will deal with both for `vaex` in next step.\n",
    "\n",
    "    For now I set the `_VaexColumn` class, taking `expressions` for columns. Two methods adeed in `_VaexDataFrame` class are `column_names()` giving a list of column names and `get_column_by_name()` selecting an `expression/column` by the `name`.\n",
    "\n",
    "    Also `dtype` method for `_VaexColumn` class is set. Copy/pasted from Pandas implementation. Will see if I get into trouble later - I will need to check possible dtypes or Vaex.\n",
    "\n",
    "- **2021/07/15**\n",
    "Adding the check for more than one chunk of data, which is set to 1 by default in the current implementation (line 36 and 246).\n",
    "\n",
    "    I started with `convert_column_to_ndarray()` method where numerical and boolean columns are turned into numpy array just like in the Pandas implementation and then all the columns would be joined together by `vaex.from_dict(columns)` where `columns` are a dictionary list of all the columns in the dataframe saved by their name. I will deal with chategorical columns later.\n",
    "    \n",
    "    Atributes `offset` and `describe_null` are set by default to 1 and a list respectively by this implementation protocol (line 68 and 71). Will probably need to apply changes to the list depending on how Vaex handles missing data. For now I am keeping it as it is.\n",
    "\n",
    "- **2021/07/16**\n",
    "Buffers!! Hurray! ðŸ˜\n",
    "\n",
    "    When we want to go from `__dataframe__` class to `vaex` dataframe class, we iterate by columns and define them as NumPy arrays, using NumPy buffers and then joining all the columns back from NumPy arrays to Vaex dataframe. No need for Vaex buffer location/understanding. I copy/pasted from Ralf's Pandas implementation.\n",
    "\n",
    "    The transformation from Vaex float dataframe back to Vaex dataframe is sucessful. The values are the same, the structure is the same. I will learn to use pytest in Jupyter Notebook to test equality of values and also buffer location.\n",
    "\n",
    "    Testing buffer location isn't very clear to me. It looks like there is a copy being made even in the Pandas implementation. I have to check manually if the values in both dataframes change together.\n",
    "\n",
    "**2021/07/19&20**\n",
    "Kshiteej confirmed copy is being made somewhere. I will have to find where the copy is being made.\n",
    "\n",
    "- **buffer_to_ndarray**\n",
    "The copy is not being made in the method buffer_to_ndarray (tested with manual collection of data).\n",
    "\n",
    "- **to dataframe!**\n",
    "The other possibility is that it is being generated when dataframe is collected from columns that are made out of buffers. And it is correct! Even `pd.Dataframe` makes a copy unless the argument copy=False is added and the version of Pandas is 1.3.0 (doesn't work in 1.2.5).\n",
    "\n",
    "**2021/07/21**\n",
    "Change Vaex dataframe protocol so it doesn't make a copy as well and then test a loop: Vaex -> Pandas -> Vaex. It works!!! Hurray! ðŸŽ‰\n",
    "\n",
    "**2021/07/22**\n",
    "Testing that the protocol works for int, float and boolean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vaex\n",
    "import pyarrow\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "\n",
    "import enum\n",
    "import collections\n",
    "import ctypes\n",
    "from typing import Any, Optional, Tuple, Dict, Iterable, Sequence\n",
    "\n",
    "DataFrameObject = Any\n",
    "ColumnObject = Any\n",
    "\n",
    "def from_dataframe_to_vaex(df : DataFrameObject) -> vaex.dataframe.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct a vaex DataFrame from ``df`` if it supports ``__dataframe__``\n",
    "    \"\"\"\n",
    "    # NOTE: commented out for roundtrip testing\n",
    "    # if isinstance(df, vaex.dataframe.DataFrame):\n",
    "    #     return df\n",
    "\n",
    "    if not hasattr(df, '__dataframe__'):\n",
    "        raise ValueError(\"`df` does not support __dataframe__\")\n",
    "\n",
    "    return _from_dataframe_to_vaex(df.__dataframe__())\n",
    "\n",
    "def _from_dataframe_to_vaex(df : DataFrameObject) -> vaex.dataframe.DataFrame:\n",
    "    \"\"\"\n",
    "    Note: not all cases are handled yet, only ones that can be implemented with\n",
    "    only Pandas. Later, we need to implement/test support for categoricals,\n",
    "    bit/byte masks, chunk handling, etc.\n",
    "    \"\"\"\n",
    "    # Check number of chunks, if there's more than one we need to iterate\n",
    "    # Alenka: it is set to 1 anyways??\n",
    "    if df.num_chunks() > 1:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # We need a dict of columns here, with each column being a numpy/arrow array (at\n",
    "    # least for now, deal with non-numpy/arrow dtypes later).\n",
    "    columns = dict()\n",
    "    _k = _DtypeKind\n",
    "    for name in df.column_names():\n",
    "        col = df.get_column_by_name(name)\n",
    "        if col.dtype[0] in (_k.INT, _k.UINT, _k.FLOAT, _k.BOOL):\n",
    "            # Simple numerical or bool dtype, turn into numpy array\n",
    "            columns[name] = convert_column_to_ndarray(col)\n",
    "        #elif col.dtype[0] == _k.CATEGORICAL:\n",
    "        #    columns[name] = convert_categorical_column(col)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Data type {col.dtype[0]} not handled yet\")\n",
    "\n",
    "    return vaex.from_dict(columns)\n",
    "\n",
    "class _DtypeKind(enum.IntEnum):\n",
    "    INT = 0\n",
    "    UINT = 1\n",
    "    FLOAT = 2\n",
    "    BOOL = 20\n",
    "    STRING = 21   # UTF-8\n",
    "    DATETIME = 22\n",
    "    CATEGORICAL = 23\n",
    "    \n",
    "def convert_column_to_ndarray(col : ColumnObject) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert an int, uint, float or bool column to a numpy array\n",
    "    \"\"\"\n",
    "    if col.offset != 0:\n",
    "        raise NotImplementedError(\"column.offset > 0 not handled yet\")\n",
    "\n",
    "    if col.describe_null[0] not in (0, 1):\n",
    "        raise NotImplementedError(\"Null values represented as masks or \"\n",
    "                                  \"sentinel values not handled yet\")\n",
    "\n",
    "    _buffer, _dtype = col.get_data_buffer()\n",
    "    return buffer_to_ndarray(_buffer, _dtype)\n",
    "\n",
    "def buffer_to_ndarray(_buffer, _dtype) -> np.ndarray:\n",
    "    # Handle the dtype\n",
    "    kind = _dtype[0]\n",
    "    bitwidth = _dtype[1]\n",
    "    _k = _DtypeKind\n",
    "    if _dtype[0] not in (_k.INT, _k.UINT, _k.FLOAT, _k.BOOL):\n",
    "        raise RuntimeError(\"Not a boolean, integer or floating-point dtype\")\n",
    "\n",
    "    _ints = {8: np.int8, 16: np.int16, 32: np.int32, 64: np.int64}\n",
    "    _uints = {8: np.uint8, 16: np.uint16, 32: np.uint32, 64: np.uint64}\n",
    "    _floats = {32: np.float32, 64: np.float64}\n",
    "    _np_dtypes = {0: _ints, 1: _uints, 2: _floats, 20: {8: bool}}\n",
    "    column_dtype = _np_dtypes[kind][bitwidth]\n",
    "\n",
    "    # No DLPack yet, so need to construct a new ndarray from the data pointer\n",
    "    # and size in the buffer plus the dtype on the column\n",
    "    ctypes_type = np.ctypeslib.as_ctypes_type(column_dtype)\n",
    "    data_pointer = ctypes.cast(_buffer.ptr, ctypes.POINTER(ctypes_type))\n",
    "\n",
    "    # NOTE: `x` does not own its memory, so the caller of this function must\n",
    "    #       either make a copy or hold on to a reference of the column or\n",
    "    #       buffer! (not done yet, this is pretty awful ...)\n",
    "    x = np.ctypeslib.as_array(data_pointer,\n",
    "                              shape=(_buffer.bufsize // (bitwidth//8),))\n",
    "\n",
    "    return x\n",
    "\n",
    "def __dataframe__(cls, nan_as_null : bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    The public method to attach to pd.DataFrame\n",
    "    We'll attach it via monkeypatching here for demo purposes. If vaex adopt\n",
    "    the protocol, this will be a regular method on vaex.dataframe.DataFrame.\n",
    "    ``nan_as_null`` is a keyword intended for the consumer to tell the\n",
    "    producer to overwrite null values in the data with ``NaN`` (or ``NaT``).\n",
    "    This currently has no effect; once support for nullable extension\n",
    "    dtypes is added, this value should be propagated to columns.\n",
    "    \"\"\"\n",
    "    return _VaexDataFrame(cls, nan_as_null=nan_as_null)\n",
    "\n",
    "# Monkeypatch the Vaex DataFrame class to support the interchange protocol\n",
    "vaex.dataframe.DataFrame.__dataframe__ = __dataframe__\n",
    "\n",
    "# Implementation of interchange protocol\n",
    "# --------------------------------------\n",
    "\n",
    "class _VaexBuffer:\n",
    "    \"\"\"\n",
    "    Data in the buffer is guaranteed to be contiguous in memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x : np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Handle only regular columns (= numpy arrays) for now.\n",
    "        \"\"\"\n",
    "        if not x.strides == (x.dtype.itemsize,):\n",
    "            # Array is not contiguous - this is possible to get in Pandas,\n",
    "            # there was some discussion on whether to support it. Som extra\n",
    "            # complexity for libraries that don't support it (e.g. Arrow),\n",
    "            # but would help with numpy-based libraries like Pandas.\n",
    "            raise RuntimeError(\"Design needs fixing - non-contiguous buffer\")\n",
    "\n",
    "        # Store the numpy array in which the data resides as a private\n",
    "        # attribute, so we can use it to retrieve the public attributes\n",
    "        self._x = x\n",
    "    \n",
    "    @property\n",
    "    def bufsize(self) -> int:\n",
    "        \"\"\"\n",
    "        Buffer size in bytes\n",
    "        \"\"\"\n",
    "        return self._x.size * self._x.dtype.itemsize\n",
    "    \n",
    "    @property\n",
    "    def ptr(self) -> int:\n",
    "        \"\"\"\n",
    "        Pointer to start of the buffer as an integer\n",
    "        \"\"\"\n",
    "        return self._x.__array_interface__['data'][0]\n",
    "\n",
    "class _VaexColumn:\n",
    "    \"\"\"\n",
    "    A column object, with only the methods and properties required by the\n",
    "    interchange protocol defined.\n",
    "    A column can contain one or more chunks. Each chunk can contain either one\n",
    "    or two buffers - one data buffer and (depending on null representation) it\n",
    "    may have a mask buffer.\n",
    "    Note: this Column object can only be produced by ``__dataframe__``, so\n",
    "          doesn't need its own version or ``__column__`` protocol.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, column : vaex.expression.Expression) -> None:\n",
    "        \"\"\"\n",
    "        Note: doesn't deal with extension arrays yet, just assume an \n",
    "        expression for now.\n",
    "        \"\"\"\n",
    "        if not isinstance(column, vaex.expression.Expression):\n",
    "            raise NotImplementedError(\"Columns of type {} not handled \"\n",
    "                                      \"yet\".format(type(column)))\n",
    "\n",
    "        # Store the column as a private attribute\n",
    "        self._col = column\n",
    "        \n",
    "    @property\n",
    "    def offset(self) -> int:\n",
    "        \"\"\"\n",
    "        Offset of first element. Always zero.\n",
    "        \"\"\"\n",
    "        return 0\n",
    "        \n",
    "    @property\n",
    "    def dtype(self) -> Tuple[enum.IntEnum, int, str, str]:\n",
    "        \"\"\"\n",
    "        Dtype description as a tuple ``(kind, bit-width, format string, endianness)``\n",
    "        Kind :\n",
    "            - INT = 0\n",
    "            - UINT = 1\n",
    "            - FLOAT = 2\n",
    "            - BOOL = 20\n",
    "            - STRING = 21   # UTF-8\n",
    "            - DATETIME = 22\n",
    "            - CATEGORICAL = 23\n",
    "        Bit-width : the number of bits as an integer\n",
    "        Format string : data type description format string in Apache Arrow C\n",
    "                        Data Interface format.\n",
    "        Endianness : current only native endianness (``=``) is supported\n",
    "        Notes:\n",
    "            - Kind specifiers are aligned with DLPack where possible (hence the\n",
    "              jump to 20, leave enough room for future extension)\n",
    "            - Masks must be specified as boolean with either bit width 1 (for bit\n",
    "              masks) or 8 (for byte masks).\n",
    "            - Dtype width in bits was preferred over bytes\n",
    "            - Endianness isn't too useful, but included now in case in the future\n",
    "              we need to support non-native endianness\n",
    "            - Went with Apache Arrow format strings over NumPy format strings\n",
    "              because they're more complete from a dataframe perspective\n",
    "            - Format strings are mostly useful for datetime specification, and\n",
    "              for categoricals.\n",
    "            - For categoricals, the format string describes the type of the\n",
    "              categorical in the data buffer. In case of a separate encoding of\n",
    "              the categorical (e.g. an integer to string mapping), this can\n",
    "              be derived from ``self.describe_categorical``.\n",
    "            - Data types not included: complex, Arrow-style null, binary, decimal,\n",
    "              and nested (list, struct, map, union) dtypes.\n",
    "        \"\"\"\n",
    "        dtype = self._col.dtype\n",
    "        return self._dtype_from_vaexdtype(dtype)\n",
    "    \n",
    "    def _dtype_from_vaexdtype(self, dtype) -> Tuple[enum.IntEnum, int, str, str]:\n",
    "        \"\"\"\n",
    "        See `self.dtype` for details\n",
    "        \"\"\"\n",
    "        # Alenka TODO!!\n",
    "        \n",
    "        \n",
    "        # Note: 'c' (complex) not handled yet (not in array spec v1).\n",
    "        #       'b', 'B' (bytes), 'S', 'a', (old-style string) 'V' (void) not handled\n",
    "        #       datetime and timedelta both map to datetime (is timedelta handled?)\n",
    "        _k = _DtypeKind\n",
    "        _np_kinds = {'i': _k.INT, 'u': _k.UINT, 'f': _k.FLOAT, 'b': _k.BOOL,\n",
    "                     'U': _k.STRING,\n",
    "                     'M': _k.DATETIME, 'm': _k.DATETIME}\n",
    "        kind = _np_kinds.get(dtype.kind, None)\n",
    "        if kind is None:\n",
    "            # Not a NumPy dtype. Check if it's a categorical maybe\n",
    "            if isinstance(dtype, pd.CategoricalDtype):\n",
    "                kind = 23\n",
    "            else:\n",
    "                raise ValueError(f\"Data type {dtype} not supported by exchange\"\n",
    "                                 \"protocol\")\n",
    "\n",
    "        if kind not in (_k.INT, _k.UINT, _k.FLOAT, _k.BOOL, _k.CATEGORICAL):\n",
    "            raise NotImplementedError(f\"Data type {dtype} not handled yet\")\n",
    "\n",
    "        bitwidth = dtype.numpy.itemsize * 8\n",
    "        format_str = dtype.numpy.str\n",
    "        endianness = dtype.byteorder if not kind == _k.CATEGORICAL else '='\n",
    "        return (kind, bitwidth, format_str, endianness)\n",
    "    \n",
    "    @property\n",
    "    def describe_null(self) -> Tuple[int, Any]:\n",
    "        \"\"\"\n",
    "        Return the missing value (or \"null\") representation the column dtype\n",
    "        uses, as a tuple ``(kind, value)``.\n",
    "        Kind:\n",
    "            - 0 : non-nullable\n",
    "            - 1 : NaN/NaT\n",
    "            - 2 : sentinel value\n",
    "            - 3 : bit mask\n",
    "            - 4 : byte mask\n",
    "        Value : if kind is \"sentinel value\", the actual value. None otherwise.\n",
    "        \"\"\"\n",
    "        _k = _DtypeKind\n",
    "        kind = self.dtype[0]\n",
    "        value = None\n",
    "        if kind == _k.FLOAT:\n",
    "            null = 1  # np.nan\n",
    "        elif kind == _k.DATETIME:\n",
    "            null = 1  # np.datetime64('NaT')\n",
    "        elif kind in (_k.INT, _k.UINT, _k.BOOL):\n",
    "            # TODO: check if extension dtypes are used once support for them is\n",
    "            #       implemented in this procotol code\n",
    "            null = 0  # integer and boolean dtypes are non-nullable\n",
    "        elif kind == _k.CATEGORICAL:\n",
    "            # Null values for categoricals are stored as `-1` sentinel values\n",
    "            # in the category date (e.g., `col.values.codes` is int8 np.ndarray)\n",
    "            null = 2\n",
    "            value = -1\n",
    "        else:\n",
    "            raise NotImplementedError(f'Data type {self.dtype} not yet supported')\n",
    "\n",
    "        return null, value\n",
    "    \n",
    "    def get_data_buffer(self) -> Tuple[_VaexBuffer, Any]:  # Any is for self.dtype tuple\n",
    "        \"\"\"\n",
    "        Return the buffer containing the data.\n",
    "        \"\"\"\n",
    "        _k = _DtypeKind\n",
    "        if self.dtype[0] in (_k.INT, _k.UINT, _k.FLOAT, _k.BOOL):\n",
    "            buffer = _VaexBuffer(self._col.to_numpy())\n",
    "            dtype = self.dtype\n",
    "        elif self.dtype[0] == _k.CATEGORICAL:\n",
    "            codes = self._col.values.codes\n",
    "            buffer = _VaexBuffer(codes)\n",
    "            dtype = self._dtype_from_pandasdtype(codes.dtype)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Data type {self._col.dtype} not handled yet\")\n",
    "\n",
    "        return buffer, dtype\n",
    "    \n",
    "class _VaexDataFrame:\n",
    "    \"\"\"\n",
    "    A data frame class, with only the methods required by the interchange\n",
    "    protocol defined.\n",
    "    Instances of this (private) class are returned from\n",
    "    ``vaex.dataframe.DataFrame.__dataframe__`` as objects with the methods and\n",
    "    attributes defined on this class.\n",
    "    \"\"\"\n",
    "    def __init__(self, df : vaex.dataframe.DataFrame, nan_as_null : bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Constructor - an instance of this (private) class is returned from\n",
    "        `vaex.dataframe.DataFrame.__dataframe__`.\n",
    "        \"\"\"\n",
    "        self._df = df\n",
    "        # ``nan_as_null`` is a keyword intended for the consumer to tell the\n",
    "        # producer to overwrite null values in the data with ``NaN`` (or ``NaT``).\n",
    "        # This currently has no effect; once support for nullable extension\n",
    "        # dtypes is added, this value should be propagated to columns.\n",
    "        self._nan_as_null = nan_as_null\n",
    "        \n",
    "    def num_chunks(self) -> int:\n",
    "        return 1\n",
    "        \n",
    "    def column_names(self) -> Iterable[str]:\n",
    "        return self._df.get_column_names()\n",
    "    \n",
    "    def get_column_by_name(self, name: str) -> _VaexColumn:\n",
    "        return _VaexColumn(self._df[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Adding some checks while constructing the methods.\n",
    "\n",
    "**Construct `vaex` dataframe from `np.array` and checking if it is a `vaex` dataframe.** <br>\n",
    "**Testing for different types of columns.** <br>\n",
    "**Testing `.dtype` attribute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe is of vaex type.\n",
      "This column is an expression.\n",
      "data type of a column: float64\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.5, 2.5, 3.5])\n",
    "y = np.array([9.2, 10.5, 11.8])\n",
    "df = vaex.from_arrays(x=x, y=y)\n",
    "df.x\n",
    "\n",
    "# Print if df is vaex dataframe\n",
    "text = \"\"\n",
    "if isinstance(df, vaex.dataframe.DataFrame):\n",
    "    text = \"is\" \n",
    "else:\n",
    "    text = \"is not\"\n",
    "print(f\"This dataframe {text} of vaex type.\")\n",
    "    \n",
    "# Print if a column is expression (array, arrow, ...)\n",
    "text2 = \"\"\n",
    "if isinstance(df.x, vaex.expression.Expression):\n",
    "    text2 = \"is\" \n",
    "else:\n",
    "    text2 = \"is not\"\n",
    "print(f\"This column {text2} an expression.\")\n",
    "\n",
    "# Print dtype\n",
    "print(f\"data type of a column: {df.x.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructing `vaex` dataframe from dictionary of numpy arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">   y</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">1.5</td><td style=\"text-align: right;\"> 9.2</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">2.5</td><td style=\"text-align: right;\">10.5</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i></td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">11.8</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x     y\n",
       "  0  1.5   9.2\n",
       "  1  2.5  10.5\n",
       "  2  3.5  11.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = dict()\n",
    "for name in df.get_column_names():\n",
    "    columns[name] = df[name].values\n",
    "vaex.from_dict(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit tests\n",
    "\n",
    "**Testing `from_dataframe()` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                            </th><th style=\"text-align: right;\">  x</th><th style=\"text-align: right;\">   y</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i></td><td style=\"text-align: right;\">1.5</td><td style=\"text-align: right;\"> 9.2</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i></td><td style=\"text-align: right;\">2.5</td><td style=\"text-align: right;\">10.5</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i></td><td style=\"text-align: right;\">3.5</td><td style=\"text-align: right;\">11.8</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "  #    x     y\n",
       "  0  1.5   9.2\n",
       "  1  2.5  10.5\n",
       "  2  3.5  11.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_dataframe_to_vaex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataframe is of vaex type.\n",
      "This column is an expression.\n",
      "data type of a column: float64\n"
     ]
    }
   ],
   "source": [
    "df_transf = from_dataframe_to_vaex(df)\n",
    "\n",
    "# Print if df is vaex dataframe\n",
    "text = \"\"\n",
    "if isinstance(df_transf, vaex.dataframe.DataFrame):\n",
    "    text = \"is\" \n",
    "else:\n",
    "    text = \"is not\"\n",
    "print(f\"This dataframe {text} of vaex type.\")\n",
    "    \n",
    "# Print if a column is expression (array, arrow, ...)\n",
    "text2 = \"\"\n",
    "if isinstance(df_transf.x, vaex.expression.Expression):\n",
    "    text2 = \"is\" \n",
    "else:\n",
    "    text2 = \"is not\"\n",
    "print(f\"This column {text2} an expression.\")\n",
    "\n",
    "# Print the call of dtype\n",
    "print(f\"data type of a column: {df_transf.x.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pytest in Notebook with ipytest.\n",
    "\n",
    "## 1. testing `from_dataframe_to_vaex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #    a     b    rhs_a    rhs_b\n",
      "  0  1.5   9.2      1.5      9.2\n",
      "  1  2.5  10.5      2.5     10.5\n",
      "  2  3.5  11.8      3.5     11.8\n",
      "[False False False]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Researching how Maartens code checks for dataframe equality (https://stackoverflow.com/questions/59875975/vaex-check-for-equality-between-two-frames)\n",
    "# In Vaex testing expressions are turned into lists and then the list are asserted (I will use in later versions)\n",
    "df_1 = vaex.from_dict(data=dict(a=[1.5, 2.5, 3.5], b=[9.2, 10.5, 11.8]))\n",
    "df_2 = from_dataframe_to_vaex(df_1)\n",
    "\n",
    "df_ = df_1.join(df_2, rprefix='rhs_')  # join based on rows number\n",
    "print(df_)\n",
    "\n",
    "#Simpe print to see the result\n",
    "print((df_['a'] != df_[\"rhs_\" + 'a']).values)\n",
    "print((df_['a'] != df_[\"rhs_\" + 'a']).sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining above code as a function to use it\n",
    "# NOTE: it might neglect missing values!\n",
    "\n",
    "def func_equality_dataframes(df1, df2):\n",
    "    df = df1.join(df2, rprefix='rhs_')  # join based on rows number\n",
    "    column_names = df1.get_column_names()\n",
    "    \n",
    "    check = all((df[name] != df[\"rhs_\" + name]).sum() == 0 for name in column_names)\n",
    "    return check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                                                [100%]\n",
      "1 passed in 0.04s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "# testing from_dataframe on vaex.from_arrays\n",
    "\n",
    "def test_dataframe_float1():\n",
    "    df1 = vaex.from_arrays(x=x, y=y)\n",
    "    df2 = from_dataframe_to_vaex(df1)\n",
    "\n",
    "    assert func_equality_dataframes(df1,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                                                [100%]\n",
      "1 passed in 0.02s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "# testing from_dataframe on vaex.from_dict\n",
    "\n",
    "def test_dataframe_float2():\n",
    "    df1 = vaex.from_dict(data=dict(a=[1.5, 2.5, 3.5], b=[9.2, 10.5, 11.8]))\n",
    "    df2 = from_dataframe_to_vaex(df1)\n",
    "    \n",
    "    assert func_equality_dataframes(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. testing two different Vaex dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                                                [100%]\n",
      "1 passed in 0.04s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "\n",
    "def test_dataframe_float3():\n",
    "    y2 = np.array([9.2, 10.5, 11])\n",
    "    df1 = vaex.from_arrays(x=x, y=y)\n",
    "    df2 = vaex.from_arrays(x=x, y=y2)\n",
    "    \n",
    "    assert not func_equality_dataframes(df1,df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing buffer pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                                                [100%]\n",
      "1 passed in 0.02s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "# Testing buffer pointer for complete from_dataframe method\n",
    "\n",
    "def test_buffer_location():\n",
    "    b1 = df.x.to_numpy().__array_interface__['data'][0]\n",
    "    b2 = from_dataframe_to_vaex(df).x.to_numpy().__array_interface__['data'][0]\n",
    "\n",
    "    assert b1 == b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                                                                                                                [100%]\n",
      "1 passed in 0.01s\n"
     ]
    }
   ],
   "source": [
    "%%run_pytest[clean]\n",
    "# Testing buffer pointer for buffer_to_ndarray part of the method\n",
    "\n",
    "def test_buffer_to_ndarray():\n",
    "\n",
    "    # Test data\n",
    "    #x = np.array([1.5, 2.5, 3.5])\n",
    "    #y = np.array([9.2, 10.5, 11.8])\n",
    "    #df = vaex.from_arrays(x=x, y=y)\n",
    "    \n",
    "    # _buffer.ptr\n",
    "    buffer_start = df.x.to_numpy().__array_interface__['data'][0]\n",
    "    print(buffer_start)\n",
    "    \n",
    "    # get_data_buffer\n",
    "    buffer = _VaexBuffer(df.x.to_numpy())\n",
    "    dtype = df.x.dtype\n",
    "    \n",
    "    print(dtype.kind)\n",
    "    print(dtype.numpy.itemsize)\n",
    "    print(dtype.numpy.str)\n",
    "    \n",
    "    # column_type\n",
    "    kind = 2 #dtype.kind = 'f' -> _DtypeKind = FLOAT = 3\n",
    "    bitwidth = dtype.numpy.itemsize * 8\n",
    "\n",
    "    _ints = {8: np.int8, 16: np.int16, 32: np.int32, 64: np.int64}\n",
    "    _uints = {8: np.uint8, 16: np.uint16, 32: np.uint32, 64: np.uint64}\n",
    "    _floats = {32: np.float32, 64: np.float64}\n",
    "    _np_dtypes = {0: _ints, 1: _uints, 2: _floats, 20: {8: bool}}\n",
    "    column_dtype = _np_dtypes[kind][bitwidth]\n",
    "\n",
    "    print(column_dtype)\n",
    "    \n",
    "    # bufsize\n",
    "    bufsize = df.x.values.size*df.x.dtype.numpy.itemsize\n",
    "    \n",
    "    # getting array from buffer \n",
    "    ctypes_type = np.ctypeslib.as_ctypes_type(column_dtype)\n",
    "    data_pointer = ctypes.cast(buffer_start, ctypes.POINTER(ctypes_type))\n",
    "    x_new = np.ctypeslib.as_array(data_pointer,\n",
    "                              shape=(bufsize // (bitwidth//8),))\n",
    "    \n",
    "    # What is the pointer?\n",
    "    x_new.__array_interface__['data'][0]\n",
    "    \n",
    "    df_new = vaex.from_arrays(x=x_new, y=y)\n",
    "    buffer_end = df_new.x.to_numpy().__array_interface__['data'][0]\n",
    "    \n",
    "    assert buffer_start == buffer_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
